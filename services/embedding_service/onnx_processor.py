#!/usr/bin/env python3
"""
ONNX Embedding Processor for PikaHelper RAG System
Handles Vietnamese text embedding using ONNX models
"""

import os
import numpy as np
from transformers import AutoTokenizer, AutoModel
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
import logging
from datetime import datetime
import torch

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ONNXEmbeddingProcessor:
    """Vietnamese embedding processor using sentence-transformers (fallback from ONNX)"""
    
    def __init__(self, model_path: str):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.embedding_dim = 1024  # Default dimension
        self.max_seq_length = 512
        self._initialize_model()
    
    def _initialize_model(self):
        """Initialize sentence-transformers model (fallback from ONNX)"""
        try:
            # Check if model directory exists
            if not os.path.exists(self.model_path):
                logger.error(f"âŒ Model directory not found: {self.model_path}")
                raise FileNotFoundError(f"Model directory not found: {self.model_path}")
            
            # List model files
            files = os.listdir(self.model_path)
            logger.info(f"ğŸ“ Model files: {files}")
            
            # Try to load as sentence-transformers model first
            try:
                logger.info("ğŸ”„ Trying to load as sentence-transformers model...")
                self.model = SentenceTransformer(self.model_path)
                self.embedding_dim = self.model.get_sentence_embedding_dimension()
                logger.info(f"âœ… Sentence-transformers model loaded from local directory")
                logger.info(f"ğŸ“Š Embedding dimension: {self.embedding_dim}")
                return
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load as sentence-transformers: {e}")
            
            # Fallback to download from Hugging Face
            logger.info("ğŸ”„ Loading Vietnamese model from Hugging Face...")
            self.model = SentenceTransformer("AITeamVN/Vietnamese_Embedding")
            self.embedding_dim = self.model.get_sentence_embedding_dimension()
            
            logger.info(f"âœ… Vietnamese model loaded from Hugging Face")
            logger.info(f"ğŸ“Š Embedding dimension: {self.embedding_dim}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize model: {e}")
            raise e
    
    def preprocess_text(self, text: str) -> str:
        """Preprocess Vietnamese text for embedding generation"""
        if not text or not isinstance(text, str):
            return ""
        
        try:
            # Basic text cleaning
            text = text.strip()
            text = " ".join(text.split())
            
            # Vietnamese text preprocessing
            text = self._vietnamese_preprocessing(text)
            
            # Truncate if too long
            if len(text) > 8000:
                text = text[:8000]
                logger.warning("âš ï¸ Text truncated to 8000 characters")
            
            return text
            
        except Exception as e:
            logger.warning(f"âš ï¸ Text preprocessing failed: {e}")
            return text.strip()
    
    def _vietnamese_preprocessing(self, text: str) -> str:
        """Vietnamese-specific text preprocessing"""
        try:
            # Try to use underthesea for Vietnamese word segmentation
            from underthesea import word_tokenize
            
            # Normalize Vietnamese text
            text = text.lower()
            
            # Tokenize using underthesea (better for Vietnamese)
            tokens = word_tokenize(text, format="text")
            
            # Join tokens with spaces for better embedding
            processed_text = " ".join(tokens.split())
            
            return processed_text
            
        except ImportError:
            logger.warning("âš ï¸ underthesea not available, using basic preprocessing")
            return text
        except Exception as e:
            logger.warning(f"âš ï¸ Vietnamese preprocessing error: {e}")
            return text
    
    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings for a batch of texts using sentence-transformers"""
        if not texts:
            return []
        
        try:
            # Preprocess texts
            processed_texts = [self.preprocess_text(text) for text in texts]
            logger.info(f"ğŸ”„ Processing {len(processed_texts)} texts")
            
            # Generate embeddings using sentence-transformers
            logger.info("ğŸ”„ Running sentence-transformers inference...")
            embeddings = self.model.encode(processed_texts, convert_to_tensor=False)
            
            logger.info(f"ğŸ“Š Embeddings shape: {embeddings.shape}")
            logger.info(f"ğŸ“Š Embedding dimension: {embeddings.shape[1]}")
            
            # Convert to list of lists
            embeddings_list = embeddings.tolist()
            
            return embeddings_list
            
        except Exception as e:
            logger.error(f"âŒ Error generating embeddings: {e}")
            import traceback
            traceback.print_exc()
            # Return zero embeddings for failed cases
            return [[0.0] * self.embedding_dim for _ in texts]
    
    def process_single_text(self, text: str) -> List[float]:
        """Process a single text and return embedding"""
        embeddings = self.generate_embeddings([text])
        return embeddings[0] if embeddings else [0.0] * self.embedding_dim
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information"""
        return {
            "model_path": self.model_path,
            "embedding_dim": self.embedding_dim,
            "max_seq_length": self.max_seq_length,
            "model_name": getattr(self.model, 'model_name', 'Unknown') if self.model else 'Unknown',
            "model_type": "sentence-transformers"
        }

def test_onnx_processor():
    """Test function for ONNX processor"""
    try:
        model_path = "/app/models/embedding"
        
        if not os.path.exists(model_path):
            logger.error(f"âŒ Model path not found: {model_path}")
            return None
        
        logger.info("ğŸ”„ Initializing ONNX processor...")
        processor = ONNXEmbeddingProcessor(model_path)
        
        # Test with Vietnamese sentences
        test_sentences = [
            "Xin chÃ o, tÃ´i lÃ  trá»£ lÃ½ AI chuyÃªn vá» hÆ°á»›ng dáº«n game PokeMMO",
            "LÃ m tháº¿ nÃ o Ä‘á»ƒ táº£i game PokeMMO trÃªn Ä‘iá»‡n thoáº¡i?",
            "HÆ°á»›ng dáº«n hoÃ n thÃ nh cá»‘t truyá»‡n Pokemon Fire Red",
            "CÃ¡ch kiáº¿m tiá»n hiá»‡u quáº£ trong PokeMMO",
            "XÃ¢y dá»±ng Ä‘á»™i hÃ¬nh PvP máº¡nh nháº¥t"
        ]
        
        logger.info("ğŸ”„ Testing embedding generation...")
        embeddings = processor.generate_embeddings(test_sentences)
        
        if embeddings:
            logger.info(f"âœ… Generated {len(embeddings)} embeddings")
            logger.info(f"ğŸ“Š Embedding dimension: {len(embeddings[0])}")
            logger.info(f"ğŸ“Š First embedding sample: {embeddings[0][:5]}")
            
            # Test similarity
            if len(embeddings) >= 2:
                from sklearn.metrics.pairwise import cosine_similarity
                sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
                logger.info(f"ğŸ“ Similarity between first two: {sim:.4f}")
            
            return embeddings
        else:
            logger.error("âŒ Failed to generate embeddings")
            return None
            
    except Exception as e:
        logger.error(f"âŒ ONNX processor test failed: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    test_onnx_processor()
